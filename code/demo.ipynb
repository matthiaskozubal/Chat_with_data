{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPY7L1sBFeJzZrMArYVzBr8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthiaskozubal/Chat_with_data/blob/main/code/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat with data\n",
        "Dynamic, LLM-powered quering over PDFs, using either predefined PDFs or yours (from your google drive).\n",
        "\n",
        "## How to use\n",
        "1. **Run code**:\n",
        "  - Click `Runtime` -> `Run all` or hit `Ctrl+F9`\n",
        "2. **Choose PDFs source**:\n",
        "  - When prompted in the 'User Input' section:\n",
        "    - type **author's** or hit **Enter** (to use predefined PDFs)\n",
        "    - type **user's** and ensure (to use your PDFs):\n",
        "      - a folder named `PDFs` is in your Google Drive with your PDFs inside"
      ],
      "metadata": {
        "id": "X6-dc12WRk5V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "2h09FiLyx2Tt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "5cA0uUhAyHwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3GqXjJH8NkT",
        "outputId": "3bce28c0-0340-47ec-975f-a38b03bd49a7"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.310-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.21)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.40 (from langchain)\n",
            "  Downloading langsmith-0.0.43-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.310 langsmith-0.0.43 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (3.16.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from google.colab import drive\n",
        "from langchain.document_loaders import PyPDFLoader"
      ],
      "metadata": {
        "id": "U701MpH0x-fv"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0qjH_8p904hT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "hh2VPDS8yL52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verbose\n",
        "VERBOSE = True"
      ],
      "metadata": {
        "id": "pZj12D0T3nox"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Author's data (hosted on GitHub)\n",
        "GITHUB_USERNAME = 'matthiaskozubal'\n",
        "REPO = 'Chat_with_data'\n",
        "BRANCH = 'main'\n",
        "DATA_PATH = 'data'"
      ],
      "metadata": {
        "id": "K0k-iFdo0hnZ"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User's data (hosted on Google Drive)\n",
        "PREDEFINED_GOOGLE_DRIVE_FOLDER_PATH = 'content/drive/My Drive/PDFs'"
      ],
      "metadata": {
        "id": "tvmFfaWHyNRF"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "HUItie_vyJdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_user_choice(verbose=False):\n",
        "  PDFs_source_choice = input(f\"Choose PDF source (author's/user's) [default: author's]: \")\n",
        "  if PDFs_source_choice not in ['author\\'s', 'user\\'s']:\n",
        "    PDFs_source_choice = 'author\\'s'\n",
        "\n",
        "  if verbose:\n",
        "    print(PDFs_source_choice)\n",
        "\n",
        "  return PDFs_source_choice\n",
        "\n",
        "# PDFs_source_choice = get_user_choice(verbose=True)"
      ],
      "metadata": {
        "id": "gNjsfhSiwwo0"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def connect_to_google_drive():\n",
        "\tdrive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "A4P5Vniwwwcf"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_PDFs_urls(GITHUB_USERNAME, REPO, BRANCH, DATA_PATH, verbose=False):\n",
        "  # construct url to github data folder\n",
        "  data_folder_url = f\"https://github.com/{GITHUB_USERNAME}/{REPO}/tree/{BRANCH}/{DATA_PATH}\"\n",
        "\n",
        "  # construct partial url to retrieve each file\n",
        "  file_partial_url = f\"https://raw.githubusercontent.com/{GITHUB_USERNAME}/{REPO}/{BRANCH}\"\n",
        "\n",
        "  # get files metada\n",
        "  response = requests.get(data_folder_url)\n",
        "  if response.status_code == 200:\n",
        "    response_json = response.json()\n",
        "    files = response_json['payload']['tree']['items']\n",
        "    file_paths = [file_name['path'] for file_name in files if file_name['contentType'] == 'file']\n",
        "    file_urls = ['/'.join([file_partial_url, file_path.replace(' ', '%20')]) for file_path in file_paths]\n",
        "    # file_urls = ['/'.join([partial_url, file_path]) for file_path in file_paths]\n",
        "    if verbose:\n",
        "      print(40*'#', ' ', 'File urls:' , 40*'#' , ' ')\n",
        "      for file_url in file_urls:\n",
        "        print(file_url)\n",
        "  else:\n",
        "    print(f\"Failed to fetch the API, status code: {response.status_code}\")\n",
        "\n",
        "  return file_urls\n",
        "\n",
        "# _ = get_PDFs_urls(GITHUB_USERNAME, REPO, BRANCH, DATA_PATH, verbose=True)"
      ],
      "metadata": {
        "id": "_TCpoRaM2Q3W"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_PDFs(PDFs_source_choice, PREDEFINED_FOLDER_PATH, verbose=False):\n",
        "  if PDFs_source_choice == 'author\\'s':\n",
        "    print(f\"Using author's data\")\n",
        "    file_urls = get_PDFs_urls(GITHUB_USERNAME, REPO, BRANCH, FOLDER_PATH, verbose=VERBOSE)\n",
        "    # pdfs = load PDFs\n",
        "  elif PDFs_source_choice == 'user\\'s':\n",
        "    print(f\"Using user's data\")\n",
        "    # mount their google drive\n",
        "    if os.path.exists(PREDEFINED_FOLDER_PATH):\n",
        "        pdf_files = [f for f in os.listdir(PREDEFINED_FOLDER_PATH) if f.endswith('.pdf')]\n",
        "        # pdfs = connect_to_drive() and do what?\n",
        "\n",
        "  if verbose:\n",
        "    print(f\"{folder_link}: {PREDEFINED_FOLDER_PATH}\")\n",
        "\n",
        "  # return ...\n",
        "# _ = query_over_PDFs(PDFs_source_choice, PREDEFINED_FOLDER_PATH, verbose=True)"
      ],
      "metadata": {
        "id": "R22I_7Xl-DQ0"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_user_question(verbose=False):\n",
        "  user_question = input(f\"Ask a question to the PDFs\")\n",
        "  if user_question == '':\n",
        "    user_question = '''\n",
        "      What is the bias and variance in terms of machine learning?\n",
        "      '''\n",
        "  if verbose:\n",
        "    print(user_question)\n",
        "\n",
        "  return user_question\n",
        "\n",
        "# user_question = get_user_question(verbose=True)"
      ],
      "metadata": {
        "id": "e9nw3x8rAWua"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_split_embeed_store_PDFs(file_urls):\n",
        "  # https://learn.deeplearning.ai/langchain-chat-with-your-data/lesson/3/document-splitting\n",
        "\n",
        "  # load\n",
        "  pass\n",
        "\n",
        "  # split\n",
        "  from langchain.text_splitter import CharacterTextSplitter\n",
        "  text_splitter = CharacterTextSplitter(\n",
        "    separator=\"\\n\",\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=150,\n",
        "    length_function=len\n",
        "  )\n",
        "  docs = text_splitter.split_documents(pages)\n",
        "\n",
        "  # embeed\n",
        "\n",
        "  # store\n"
      ],
      "metadata": {
        "id": "VIJyagGMFQlV"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_over_PDFs(verbose=False):\n",
        "    pass"
      ],
      "metadata": {
        "id": "-nl2rLMzEd8W"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "jD2mRlF5AOT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PDFs_source_choice = get_user_choice(verbose=VERBOSE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LslsJt4Twv54",
        "outputId": "90b3b97a-d54a-476f-f9c5-dacd7a48b96d"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choose PDF source (author's/user's) [default: author's]: \n",
            "author's\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_urls = get_PDFs_urls(GITHUB_USERNAME, REPO, BRANCH, FOLDER_PATH, verbose=VERBOSE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4UYsveK3xAA",
        "outputId": "12a487c8-036c-42ba-f5bd-b5477f96d450"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########################################   File urls: ########################################  \n",
            "https://raw.githubusercontent.com/matthiaskozubal/Chat_with_data/main/data/A%20Brief%20Introduction%20to%20Machine%20Learning%20for%20Engineers%20-%20Osvaldo%20Simeone.pdf\n",
            "https://raw.githubusercontent.com/matthiaskozubal/Chat_with_data/main/data/Algorithmic%20Aspects%20of%20Machine%20Learning%20-%20Ankur%20Moitra%20(2014).pdf\n",
            "https://raw.githubusercontent.com/matthiaskozubal/Chat_with_data/main/data/An%20introduction%20to%20variable%20and%20feature%20selection%20-%20Isabelle%20Guyon,%20André%20Elisseeff.pdf\n",
            "https://raw.githubusercontent.com/matthiaskozubal/Chat_with_data/main/data/Automated%20Machine%20Learning,%20Methods,%20Systems,%20Challenges%20-%20Frank%20Hutter,%20Lars%20Kotthoff,%20Joaquin%20Vanschoren.pdf\n",
            "https://raw.githubusercontent.com/matthiaskozubal/Chat_with_data/main/data/CAUSALITY%20FOR%20MACHINE%20LEARNING%20-%20Bernhard%20Schölkopf.pdf\n",
            "https://raw.githubusercontent.com/matthiaskozubal/Chat_with_data/main/data/Deep%20Learning%20%20-%20Ian%20Goodfellow,%20Yoshua%20Bengio,%20Aaron%20Courville.pdf\n",
            "https://raw.githubusercontent.com/matthiaskozubal/Chat_with_data/main/data/Dive%20into%20Deep%20Learning%20-%20ASTON%20ZHANG,%20ZACHARY%20C.%20LIPTON,%20MU%20LI,%20AND%20ALEXANDER%20J.%20SMOLA.pdf\n",
            "https://raw.githubusercontent.com/matthiaskozubal/Chat_with_data/main/data/Foundations%20of%20Machine%20Learning,%202nd%20edition%20-%20Mehryar%20Mohri,%20Afshin,%20Rostamizadeh,%20and%20Ameet%20Talwalkar.pdf\n",
            "https://raw.githubusercontent.com/matthiaskozubal/Chat_with_data/main/data/Introductory%20Machine%20Learning%20Notes%20-%20Lorenzo%20Rosasco.pdf\n",
            "https://raw.githubusercontent.com/matthiaskozubal/Chat_with_data/main/data/Natural%20Language%20Processing%20-%20Jacob%20Eisenstein%20(2018).pdf\n",
            "https://raw.githubusercontent.com/matthiaskozubal/Chat_with_data/main/data/Pattern%20Recognition%20and%20Machine%20Learning%20-%20Bishop%20(2006).pdf\n",
            "https://raw.githubusercontent.com/matthiaskozubal/Chat_with_data/main/data/Reinforcement%20Learning,%20An%20Introduction,%202nd%20edition%20-%20Richard%20S.%20Sutton%20and%20Andrew%20G.%20Barto.pdf\n",
            "https://raw.githubusercontent.com/matthiaskozubal/Chat_with_data/main/data/Rules%20of%20Machine%20Learning,%20Best%20Practices%20for%20ML%20Engineering%20-%20Martin%20Zinkevich.pdf\n",
            "https://raw.githubusercontent.com/matthiaskozubal/Chat_with_data/main/data/Seven%20Steps%20to%20Success,%20Machine%20Learning%20in%20Practice%20-%20Daoud%20Clarke.pdf\n",
            "https://raw.githubusercontent.com/matthiaskozubal/Chat_with_data/main/data/Understanding%20Machine%20Learning,%20From%20Theory%20to%20Algorithms%20-%20Shai%20Shalev-Shwartz%20and%20Shai%20Ben-David%20(2014).pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(file_urls[2])\n",
        "pages = loader.load()#_and_split()\n",
        "# pages[19]"
      ],
      "metadata": {
        "id": "uJVzMlcG4NBV"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=1000, chunk_overlap=150, length_function=len)\n",
        "docs = text_splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "-Pr8xfJB4MuH"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2TY-eINH4vV",
        "outputId": "de326842-ad07-4aa1-e341-5443fc4c45ea"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5TspkCqH4tQ",
        "outputId": "00c2eee8-216a-441f-d6ce-d3b8431d9ca0"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pages[9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93JjDTpTIiDJ",
        "outputId": "ade49599-1ce2-4820-c488-e633a25970bd"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Guyon andElisseeff\\n−5 0 5 −2−1 012−505−2−1012\\n−0.5 00.511.5 −0.5 00.511.5−0.500.511.5−0.500.511.5\\n(a) (b)\\nFigure3:Avariableuselessbyitselfcanbeusefultogether withothers. (a)One\\nvariablehascompletely overlapping classconditional densities. Still,usingitjointlywith\\ntheothervariableimprovesclassseparabilit ycompared tousingtheothervariablealone.\\n(b)XOR-likeorchessboard-likeproblems. Theclassesconsistofdisjointclumpssuchthatin\\nprojectionontheaxestheclassconditional densities overlapperfectly.Therefore, individual\\nvariableshavenoseparation power.Still,takentogether, thevariablesprovidegoodclass\\nseparabilit y.\\n4Variable Subset Selection\\nIntheprevious section,wepresentedexamples thatillustrate theusefulness ofselecting\\nsubsetsofvariablesthattogether havegoodpredictiv epower,asopposedtorankingvari-\\nablesaccording totheirindividual predictiv epower.Wenowturntothisproblem and\\noutlinethemaindirections thathavebeentakentotackleit.Theyessentiallydivideinto\\nwrappers,ﬁlters,andembeddedmethods.Wrappersutilizethelearning machineofinter-\\nestasablackboxtoscoresubsetsofvariableaccording totheirpredictiv epower.Filters\\nselectsubsetsofvariablesasapre-processingstep,independentlyofthechosenpredictor.\\nEmbeddedmethodsperformvariableselection intheprocessoftraining andareusually\\nspeciﬁctogivenlearning machines.\\n4.1WrappersandEmbeddedMethods\\nThewrappermethodology,recentlypopularized byKohaviandJohn(1997),oﬀersasimple\\nandpowerfulwaytoaddresstheproblem ofvariableselection, regardless ofthechosen\\nlearning machine.Infact,thelearning machineisconsidered aperfectblackboxandthe\\nmethodlendsitselftotheuseofoﬀ-the-shelf machinelearningsoftwarepackages.Initsmost\\ngeneralformulation,thewrappermethodologyconsistsinusingtheprediction performance\\nofagivenlearning machinetoassesstherelativeusefulness ofsubsetsofvariables. In\\npractice, oneneedstodeﬁne:(i)howtosearchthespaceofallpossiblevariablesubsets;(ii)\\n1166', metadata={'source': '/tmp/tmpypk4uyuh/tmp.pdf', 'page': 9})"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUufLxKZH4rE",
        "outputId": "38518d07-0136-422d-bf85-aab925ed137b"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='rankingofstep5,construct asequence ofpredictors ofsamenatureusingincreasing\\nsubsetsoffeatures. Canyoumatchorimproveperformance withasmallersubset?If\\nyes,tryanon-linear predictor withthatsubset.\\n9.Doyouhavenewideas,time,computational resources, andenoughex-\\namples? Ifyes,compare severalfeatureselection methods,including yournewidea,\\ncorrelation coeﬃcients,backwardselection andembeddedmethods(Section 4).Use\\nlinearandnon-linear predictors. Selectthebestapproachwithmodelselection (Sec-\\ntion6).\\n10.Doyouwantastablesolution (toimproveperformance and/orunderstanding)?\\nIfyes,sub-sample yourdataandredoyouranalysis forseveral“bootstraps” (Section\\n7.1).\\n2.Wecautionthereaderthatthischecklistisheuristic. Theonlyrecommendation thatisalmostsurely\\nvalidistotrythesimplestthingsﬁrst.\\n3.By“linearpredictor” wemeanlinearintheparameters. Featureconstruction mayrenderthepredictor\\nnon-linear intheinputvariables.\\n1159', metadata={'source': '/tmp/tmpypk4uyuh/tmp.pdf', 'page': 2})"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_question = get_user_question(verbose=VERBOSE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMR9I-vIATFu",
        "outputId": "ab606002-dfc8-49d2-8a2c-1aff407e9aa7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ask a question to the PDFs\n",
            "\n",
            "      What is the bias and variance in terms of machine learning.\n",
            "      \n"
          ]
        }
      ]
    }
  ]
}