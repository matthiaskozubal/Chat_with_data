{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthiaskozubal/Chat_with_data/blob/main/code/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat with data\n",
        "Dynamic, LLM-powered quering over PDFs, using either predefined PDFs or yours (from your google drive).\n",
        "\n",
        "## How to use\n",
        "1. **Run code**:\n",
        "  - Click `Runtime` -> `Run all` or hit `Ctrl+F9`\n",
        "2. **Choose PDFs source**:\n",
        "  - When prompted in the 'User Input' section:\n",
        "    - type **author's** or hit **Enter** (to use predefined PDFs)\n",
        "    - type **user's** and ensure (to use your PDFs):\n",
        "      - a folder named `PDFs` is in your Google Drive with your PDFs inside\n",
        "3. **Provide OpenAI API key**\n",
        "  - When prompted in the 'OpenAI API key' section\n",
        "  - From https://platform.openai.com/account/api-keys"
      ],
      "metadata": {
        "id": "X6-dc12WRk5V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "2h09FiLyx2Tt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "5cA0uUhAyHwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install chromadb\n",
        "!pip -q install langchain\n",
        "!pip -q install openai\n",
        "!pip -q install pypdf\n",
        "!pip -q install tiktoken"
      ],
      "metadata": {
        "id": "j3GqXjJH8NkT",
        "outputId": "a51d33e2-59a1-4091-adeb-9f38c7cdfd88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.8/479.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.9/103.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.6/276.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "import requests\n",
        "\n",
        "from google.colab import drive\n",
        "from IPython.display import display, Markdown\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "from langchain.text_splitter import CharacterTextSplitter"
      ],
      "metadata": {
        "id": "U701MpH0x-fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0qjH_8p904hT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "hh2VPDS8yL52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verbose\n",
        "VERBOSE = False"
      ],
      "metadata": {
        "id": "pZj12D0T3nox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Author's data (hosted on GitHub)\n",
        "GITHUB_USERNAME = 'matthiaskozubal'\n",
        "REPO = 'Chat_with_data'\n",
        "BRANCH = 'main'\n",
        "DATA_PATH = 'data'"
      ],
      "metadata": {
        "id": "K0k-iFdo0hnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User's data (hosted on Google Drive)\n",
        "PREDEFINED_GOOGLE_DRIVE_FOLDER_PATH = 'content/drive/My Drive/PDFs'"
      ],
      "metadata": {
        "id": "tvmFfaWHyNRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "HUItie_vyJdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_openai_api_key():\n",
        "  openai_api_key = input(f\"Provide OpenAI API key: \")\n",
        "  os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "  openai.api_key  = os.environ['OPENAI_API_KEY']"
      ],
      "metadata": {
        "id": "vtTVeOItztaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_user_choice(verbose=False):\n",
        "  PDFs_source_choice = input(f\"Choose PDF source (author's/user's) [default: author's]: \")\n",
        "  if PDFs_source_choice not in ['author\\'s', 'user\\'s']:\n",
        "    PDFs_source_choice = 'author\\'s'\n",
        "\n",
        "  if verbose:\n",
        "    print(PDFs_source_choice)\n",
        "\n",
        "  return PDFs_source_choice"
      ],
      "metadata": {
        "id": "gNjsfhSiwwo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def connect_to_google_drive():\n",
        "\tdrive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "A4P5Vniwwwcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_PDFs_urls_from_github(GITHUB_USERNAME, REPO, BRANCH, DATA_PATH, verbose=False):\n",
        "  # construct url to github data folder\n",
        "  data_folder_url = f\"https://github.com/{GITHUB_USERNAME}/{REPO}/tree/{BRANCH}/{DATA_PATH}\"\n",
        "\n",
        "  # construct partial url to retrieve each file\n",
        "  file_partial_url = f\"https://raw.githubusercontent.com/{GITHUB_USERNAME}/{REPO}/{BRANCH}\"\n",
        "\n",
        "  # get files metada\n",
        "  response = requests.get(data_folder_url)\n",
        "  if response.status_code == 200:\n",
        "    response_json = response.json()\n",
        "    files = response_json['payload']['tree']['items']\n",
        "    file_paths = [file_name['path'] for file_name in files if file_name['contentType'] == 'file']\n",
        "    file_urls = ['/'.join([file_partial_url, file_path.replace(' ', '%20')]) for file_path in file_paths]\n",
        "    # file_urls = ['/'.join([partial_url, file_path]) for file_path in file_paths]\n",
        "    if verbose:\n",
        "      print(40*'#', ' ', 'File urls:' , 40*'#' , ' ')\n",
        "      for file_url in file_urls:\n",
        "        print(file_url)\n",
        "  else:\n",
        "    print(f\"Failed to fetch the API, status code: {response.status_code}\")\n",
        "\n",
        "  return file_urls\n",
        "\n",
        "# _ = get_PDFs_urls_from_github(GITHUB_USERNAME, REPO, BRANCH, DATA_PATH, verbose=True)"
      ],
      "metadata": {
        "id": "Z93QAeK38wQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_PDFs_urls_from_user_google_drive(PREDEFINED_GOOGLE_DRIVE_FOLDER_PATH, verbose=False):\n",
        "  # mount their google drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  if os.path.exists(PREDEFINED_GOOGLE_DRIVE_FOLDER_PATH):\n",
        "      pdf_files = [f for f in os.listdir(PREDEFINED_GOOGLE_DRIVE_FOLDER_PATH) if f.endswith('.pdf')]\n",
        "      # pdfs = connect_to_drive() and do what?\n",
        "\n",
        "  if verbose:\n",
        "    print(f\"{folder_link}: {PREDEFINED_GOOGLE_DRIVE_FOLDER_PATH}\")\n",
        "\n",
        "  return file_urls"
      ],
      "metadata": {
        "id": "2iNmO55p9Mc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_PDFs_urls(PDFs_source_choice, PREDEFINED_GOOGLE_DRIVE_FOLDER_PATH, GITHUB_USERNAME, REPO, BRANCH, DATA_PATH, verbose=False):\n",
        "  if PDFs_source_choice == 'author\\'s':\n",
        "    file_urls = get_PDFs_urls_from_github(GITHUB_USERNAME, REPO, BRANCH, DATA_PATH, verbose=verbose)\n",
        "  elif PDFs_source_choice == 'USER\\'s':\n",
        "    file_urls = get_PDFs_urls_from_user_google_drive(PREDEFINED_GOOGLE_DRIVE_FOLDER_PATH, verbose=verbose)\n",
        "\n",
        "  return file_urls"
      ],
      "metadata": {
        "id": "_TCpoRaM2Q3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_split_embed_store_PDFs(file_urls):\n",
        "  # https://learn.deeplearning.ai/langchain-chat-with-your-data/lesson/3/document-splitting\n",
        "\n",
        "  # load\n",
        "  docs = []\n",
        "  for i in range(3):\n",
        "    loader = PyPDFLoader(file_urls[i])\n",
        "    document = loader.load()\n",
        "    docs.extend(document)\n",
        "\n",
        "  # split\n",
        "  text_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=1000, chunk_overlap=200, length_function=len)\n",
        "  splits = text_splitter.split_documents(document)\n",
        "\n",
        "  # embed\n",
        "  embedding = OpenAIEmbeddings()\n",
        "\n",
        "  # store\n",
        "  from langchain.vectorstores import Chroma\n",
        "  persist_directory = 'docs/chroma/'\n",
        "  vectordb = Chroma.from_documents(\n",
        "      documents = docs,\n",
        "      persist_directory=persist_directory,\n",
        "      embedding=embedding\n",
        "  )\n",
        "\n",
        "  return vectordb"
      ],
      "metadata": {
        "id": "VIJyagGMFQlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_over_PDFs(vectordb, verbose=False):\n",
        "  # query (user's or a default one)\n",
        "  query = input(f\"Ask a question to the PDFs: \\n\")\n",
        "  if query == '':\n",
        "    query = '''\n",
        "      What is the bias and variance in terms of machine learning?\n",
        "      '''\n",
        "\n",
        "  # retrieval\n",
        "  llm = OpenAI(temperature=0)\n",
        "  compressor = LLMChainExtractor.from_llm(llm)\n",
        "  compression_retriever = ContextualCompressionRetriever(\n",
        "      base_compressor=compressor,\n",
        "      base_retriever=vectordb.as_retriever()\n",
        "  )\n",
        "  compressed_docs = compression_retriever.get_relevant_documents(query)\n",
        "  print(compressed_docs)\n",
        "  # query an LLM\n",
        "  llm_chat = ChatOpenAI(temperature = 0.0)\n",
        "  response = llm_chat.call_as_llm(f\"{compressed_docs} Question: {query}\")\n",
        "\n",
        "  # response\n",
        "  display(Markdown(response))"
      ],
      "metadata": {
        "id": "-nl2rLMzEd8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "jD2mRlF5AOT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_openai_api_key()"
      ],
      "metadata": {
        "id": "m72AuAsb0owK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PDFs_source_choice = get_user_choice(verbose=VERBOSE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LslsJt4Twv54",
        "outputId": "71eed344-ce28-45bb-f5bd-eac2b4c8ded6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose PDF source (author's/user's) [default: author's]: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_urls = get_PDFs_urls(PDFs_source_choice, PREDEFINED_GOOGLE_DRIVE_FOLDER_PATH, GITHUB_USERNAME, REPO, BRANCH, DATA_PATH, verbose=VERBOSE)"
      ],
      "metadata": {
        "id": "c4UYsveK3xAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = load_split_embed_store_PDFs(file_urls)"
      ],
      "metadata": {
        "id": "bOdblNeLxfQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_over_PDFs(vectordb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "L2OTndT9xfOV",
        "outputId": "3017781c-a894-4c4e-e0ce-6056e6f3061a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ask a question to the PDFs: \n",
            "what is mars\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Mars is the fourth planet from the Sun in our solar system. It is often referred to as the \"Red Planet\" due to its reddish appearance, caused by iron oxide (rust) on its surface. Mars is a terrestrial planet with a thin atmosphere, and it has surface features similar to both the Moon and Earth. It has polar ice caps, volcanoes, canyons, and a variety of other geological formations. Mars is also known for having the largest volcano and the deepest canyon in the solar system. It has been a subject of scientific interest and exploration, with several missions sent to study its surface and search for signs of past or present life."
          },
          "metadata": {}
        }
      ]
    }
  ]
}